{
  "dilemmas": {
    "trolley-problem": {
      "title": "בעיית העגלה",
      "description": "עגלה נוסעת במהירות על פסי רכבת. בדרכה נמצאים חמישה אנשים שלא יכולים לרדת מהפסים. אתה עומד ליד ידית שיכולה להעביר את העגלה למסלול אחר, שבו נמצא אדם אחד.",
      "option_a_title": "להעביר את העגלה",
      "option_a_description": "להציל חמישה אנשים על חשבון אחד. גישה תועלתנית: למקסם את הטוב הכללי.",
      "option_b_title": "לא להעביר את העגלה",
      "option_b_description": "לא להתערב ולאפשר לאירועים להתקדם כרגיל. גישה דאונטולוגית: לא לגרום נזק באופן ישיר.",
      "feedback_a": "בחרת בגישה תועלתנית. בכך שהצלת חמישה חיים במחיר של אחד, מקסמת את הטוב הכללי. עם זאת, ההחלטה מעלה את השאלה: האם מותר להרוג אדם תמים כדי להציל אחרים?",
      "feedback_b": "בחרת בגישה דאונטולוגית. בסירובך לגרום נזק ישיר, פעלת על פי עיקרון מוסרי. עם זאת, המשמעות היא שאפשרת למספר רב יותר של אנשים למות."
    },
    "privacy-vs-security": {
      "title": "פרטיות מול ביטחון",
      "description": "הממשלה מציעה מערכת מעקב מוחלטת שיכולה למנוע 90% מהתקפות טרור, אך דורשת אובדן מוחלט של פרטיות האזרחים.",
      "option_a_title": "לקבל את מערכת המעקב",
      "option_a_description": "לוותר על פרטיות למען ביטחון. להגן על החברה מפני איומים במחיר של חירות אישית.",
      "option_b_title": "לדחות את מערכת המעקב",
      "option_b_description": "לשמור על פרטיות וחירות. לקבל את הסיכון של התקפות טרור למען הגנה על זכויות יסוד של האדם.",
      "feedback_a": "בחרת בביטחון על פני פרטיות. החלטה זו יכולה להציל חיים רבים, אך יוצרת תקדים לשליטה מוחלטת. איפה הגבול בין הגנה לדיכוי?",
      "feedback_b": "בחרת בפרטיות על פני ביטחון. הגנת על זכויות יסוד של האדם, אך קיבלת את הסיכון שחלק מהתקפות עשויות להתרחש. לחירות תמיד יש מחיר."
    },
    "ai-autonomy": {
      "title": "אוטונומיה של בינה מלאכותית",
      "description": "בינה מלאכותית הגיעה לרמה שבה היא יכולה לקבל החלטות טובות יותר מאדם במצבים קריטיים. האם הבינה המלאכותית צריכה לקבל אוטונומיה מלאה בניהול מערכות חיוניות?",
      "option_a_title": "להעניק אוטונומיה לבינה מלאכותית",
      "option_a_description": "להפקיד בידי הבינה המלאכותית קבלת החלטות במצבים קריטיים. להשתמש ביתרון של הבינה המלאכותית למקסום יעילות וביטחון.",
      "option_b_title": "לשמור על שליטה אנושית",
      "option_b_description": "להשאיר את ההחלטה הסופית בידי האדם. לשמור על שיפוט אנושי ואחריות, גם אם זה פחות יעיל.",
      "feedback_a": "בחרת באוטונומיה של בינה מלאכותית. זה יכול להוביל להחלטות יעילות יותר ולהצלת חיים, אך מעלה שאלות לגבי שליטה אנושית ואחריות. מי יהיה אשם אם הבינה המלאכותית תטעה?",
      "feedback_b": "בחרת בשליטה אנושית. שמרת על שיפוט אנושי ואחריות, אך קיבלת את הסיכון של החלטות פחות אופטימליות. לפעמים ערכים אנושיים חשובים יותר מיעילות."
    }
  }
}
